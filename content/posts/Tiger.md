---
title: TIGER & Semantic ID
date: 2025-10-20
description: 生成式推荐开山鼻祖，含金量无需多言
draft: false
categories:
  - 论文阅读
tags:
  - 生成式推荐系统
slug: tiger
katex: true
math: true
---
# TIGER

---
## 推荐系统深度学习基本流程

现有深度学习架构：
* 输入特征 → 文本嵌入 → 隐藏层（RNN，深度学习网络）  
  得到更精准的预测表征 → 预测层（通过查询与物品的相似性度量、点击，对相关物品进行排序，得到预测）
* 检索 / 召回一系列可行的候选对象，然后用排序模型对其进行排序。

---
#### 检索阶段

通过矩阵分解，在同一空间学习查询和候选的嵌入。  
为了更好地捕获数据中的非线性关系，近年来采用 **内积查询和候选嵌入到同一空间的双塔编码架构**（一个塔用于查询(用户)，另一个塔用于候选(物品)）成为主流。

为了在推理期间使用这些模型，使用候选塔创建一个存储所有物品嵌入的索引。  
对于给定查询，通过在同一个空间内嵌入查询和候选项来执行大规模检索，  
然后使用**近似最邻近搜索（ANN）**来选择给定查询嵌入的最佳候选项。
然后筛选到的物品进行内积计算排序

---
## 推荐系统存在的局限与挑战

- 召回 → 排序 → 重排，流程复杂，需要分别优化。
- 对召回阶段的依赖（庞大候选集快速筛选相关物品）  
  - 如果召回都没召回到用户感兴趣的东西，排序更不可能找到。
- 对排序阶段的局限（基于学习的排序模型 / 神经网络模型 / 对候选物品排序）。
- 对反馈循环的影响：基于用户的历史交互行为进行预测，会产生反馈循环。
- 冷启动推荐：新商品被反馈循环影响。
- 推荐的“长尾”现象：热门更热，冷门更冷。

---

## 本文工作：提出全新的推荐系统框架 TIGER
{{< figure src="/images/tiger/tiger_1.png" alt="" width="720" >}}

基于生成式检索范式并应用到序列推荐中：

1. 创建语义上有意义的 token 元组，作为每个物品的语义 ID。  
   通过生成的用户交互序列中物品的语义 ID，训练基于 Transformer 的序列到序列模型来“生成”用户将与之交互的下一个物品的语义 ID。
2. 提出 TIGER 推荐模型在各种数据集上的性能显著优于当前 SOTA 模型。
3. 展现两个关键能力：  
   - 冷启动推荐能力：能够推荐此前从未出现过的物品；  
   - 推荐多样性控制能力：可通过调节生成参数实现推荐内容的丰富性。
4. 生成式推荐新范式，为构建更具泛化能力、可解释性和灵活性的推荐系统开辟新方向。

---
## TIGER 的生成式推荐范式

提出一种构建序列推荐生成式检索模型的新范式。  
与传统的检索-排序方法不同，  
我们的方法使用 **直接预测候选物品 ID 的端到端生成模型**。

我们提出利用 Transformer 内存（参数）作为推荐系统中检索的端到端索引引擎。  
我们将提出的方法称为 **Transformer Index for GEnerative Recommenders（TIGER）**。

{{< figure src="/images/tiger/tiger_2.png" alt="ppo" width="720" >}}

图 2 展示了 TIGER 框架的整体工作流程，说明了如何将序列推荐任务转化为一个生成式检索任务。

---

## 语义 ID（Semantic ID）简介

语义 ID 示例： (2, 3, 55)，每一个数字都代表着一个稠密向量。

将物品 (item) 表示为语义 ID 序列具有许多优点：

1. **语义共享与泛化**  
   在具有语义意义的数据上训练 Transformer 允许在相似的物品之间共享知识，  
   避免在推荐模型中使用原子、随机的物品 ID 作为特征，  
   从而支持知识迁移和泛化。

2. **缓解反馈循环**  
   使用物品的语义 ID 能缓解推荐系统固有的反馈循环，  
   减少系统对热门物品的依赖，  
   并允许模型泛化到语料库中的新物品，更好地支持新物品推荐。

3. **存储与扩展性**  
   通常物品数量可达数十亿级。  
   使用有限数量的代码词组合生成语义 ID 来表示物品，  
   可显著降低物品表示的存储成本和参数规模，  
   提升系统的可扩展性。

---

#### 本工作的主要贡献

1. 提出新的基于生成检索的推荐框架 **TIGER**：  
   为每个物品分配语义 ID，并训练模型预测生成给定用户可能交互的物品语义 ID。  
2. 通过召回率和 NDCG 指标，证明 TIGER 在多个数据集上优于现有 SOTA 推荐系统。  
3. 发现生成式检索新范式在序列推荐系统中带来了两个额外能力：  
   - 推荐新的和冷门的物品，改进冷启动；  
   - 可用可调参数生成多样的推荐结果。

---
# 语义ID详解

### 定义与构成
- 语义ID是长度为\(m\)的token元组，每个token来自不同的codebook（代码簿），可唯一表示的项数等于每层codebook大小的乘积。
- 示例：语义ID\([10,21,35]\)与\([10,21,40]\)的相似度高于\([10,23,32]\)，因前两个token重叠，语义更接近。

###  关键属性
- 相似性：相似项（内容特征相似或语义嵌入接近）需具有重叠的语义ID。
- 离散化语义表示：不依赖具体物品ID，基于内容语义生成，而非物品实体本身。
- 可控可复用：组成单位（codewords）来自固定大小的codebook，大小可控且可重复利用。
- 组合式表达：如每个ID由3个token组成，每个token选自1000个候选，可表达\(1000^3=10^9\)个组合，能覆盖大规模推荐系统的物品空间。

###  与大语言模型Tokenizer的区别
| 对比维度 | 语义ID | 大语言模型Tokenizer |
|----------|--------|---------------------|
| 依赖对象 | 不依赖具体物品ID，基于内容语义 | 依赖文本序列，与物品语义无直接关联 |
| 组成来源 | 固定大小codebook的codewords | 文本语料库中的子词（如BPE分词结果） |
| 表达能力 | 组合式，覆盖物品空间能力强 | 序列式，聚焦文本语义表达 |

> [!TIP]
> > 通过语义ID的设计，使得推荐系统能够像语言模型那样“输出”目标物品，但又规避了推荐领域中 item ID/token 空间过大、实体变化频繁等根本难题。可以说，语义ID是 TIGER 成功的核心支柱之一。

### 语义ID生成方法
####  核心方法：基于RQ-VAE（残差量化变分自动编码器）
{{< figure src="/images/tiger/semantic_ID_1.png" alt="" width="920" >}}

RQ-VAE 首先通过编码器 $\mathcal{E}$ 对输入 $x$ 进行编码，以学习潜在表示：$z := \mathcal{E}(x)$

在第 0 个残差两化层（$d=0$）时，初始残差被定义为：$r_0 := z$ 
在每一层 $d$，都有一个码本（codebook）：$C_d :=$ { $e_k$ } $_{k=1}^K$
其中 $K$ 是码本的大小。（可以理解为有K个物品）

接着，$r_0$ 被量化为该层码本中最近的嵌入向量。  距离最近的嵌入为 $e_{c_d}$，其索引为：$c_0 = \arg\min_k \| r_0 - e_k \|$ 这表示第 0 个 codeword。
在下一层（$d=1$）中，残差定义为：$r_1 := r_0 - e_{c_0}$
然后与第 0 层类似，第 1 层的 codeword 通过在码本中寻找最接近 $r_1$ 的嵌入得到。
该过程递归重复 $m$ 次，以获得 $m$ 个 codeword 组成的元组：
$$
(c_0, c_1, \ldots, c_{m-1})
$$
该元组即表示语义 ID（Semantic ID）。

---

#### 重构与损失函数

一旦得到语义 ID $(c_0, \ldots, c_{m-1})$，量化后的潜在表示计算为：
$$
\hat{z} := \sum_{d=0}^{m-1} e_{c_d}
$$

然后将 $\hat{z}$ 传入解码器，以重建输入 $x$。  
RQ-VAE 的总损失定义为：
$$
\mathcal{L}(x) := \mathcal{L}\_{recon} + \mathcal{L}_{rqvae}
$$

其中：
$$
\mathcal{L}\_{recon} := \|| x - \hat{x} \||^2,
$$
$$
\mathcal{L}\_{rqvae} := \sum_{d=0}^{m-1} \big( \| sg[r_i] - e_{c_i} \|^2 + \beta \|| r_i - sg[e_{c_i}] \||^2 \big)
$$

这里 $\hat{x}$ 是解码器输出，$sg$ 表示停止梯度（stop-gradient）操作。  
该损失函数联合训练编码器、解码器和码本。

---
#### 避免 Codebook Collapse

为了防止 RQ-VAE 出现 **codebook collapse**（即大部分输入仅映射到极少数码本向量），  
采用基于 **k-means 聚类** 的码本初始化方法。  
具体做法是在首个训练批次上应用 k-means 算法，并使用聚类中心作为初始码本向量。
##### 生成示例
若经 3 层量化得到嵌入索引 $e_{c_0}=7$、$e_{c_1}=1$、$e_{c_2}=4$，  则语义 ID 为 $(7, 1, 4)$。

#### 其他量化方法对比（消融实验证实RQ-VAE最优）
| 方法 | 特点 | 不足 |
|------|------|------|
| LSH（局部敏感哈希） | 离散化速度快 | 精度低，语义保留差 |
| VQ-VAE（矢量量化变分自动编码器） | 基础量化能力 | 无语义层次粒度，无法体现粗/细分类别 |
| 基于k-means层次聚类 | 可实现层次划分 | 丢失ID间的语义关系，相似项可能无重叠ID |

#### 冲突处理
- 附加标识位：增加1位token表示语义重复，区分相同语义ID的不同物品。
- 查找表：维护“语义ID→物品ID”映射表，避免模型误判无对应物品的语义ID；仅需训练后处理1次，不影响训练效率。


# 基于语义ID的生成式检索（TIGER框架核心）
## 核心思路
- 将推荐任务转化为“序列生成”任务：通过用户历史交互物品的语义ID序列，预测下一个物品的语义ID，实现生成式检索。
#### 流程步骤
#### （1）用户序列构建
- 按时间顺序排序用户历史交互物品，形成物品序列$(item_1, ..., item_n)$。
#### （2）序列转换
- 设$(item_i)$的语义ID为$(c_{i,0}, ..., c_{i,m-1})$，将物品序列转换为语义ID序列：$(c_{1,0}, ..., c_{1,m-1}, c_{2,0}, ..., c_{2,m-1}, ..., c_{n,0}, ..., c_{n,m-1})$。
#### （3）模型训练与预测
- 模型结构：
{{< figure src="/images/tiger/Semantic_ID_2.png" alt="" width="720" >}}
- 任务目标：训练序列到序列模型，预测下一个物品的语义ID$(c_{n+1,0}, ..., c_{n+1,m-1})$。
- 特殊情况：解码器生成的语义ID可能与推荐语料库物品不匹配，但概率极低。
- 通过语义ID的设计，TIGER框架成功地将推荐系统引入了一个生成式检索的新范式，使得系统能够像语言模型那样直接“输出”目标物品。


### 实验设计与结果
#### 1. 实验基础设置
#### 基座模型与数据集

{{< figure src="/images/tiger/tiger_data_1.png" alt="" width="920" >}}
{{< figure src="/images/tiger/tiger_data_2.png" alt="" width="920" >}}
#### 2. 核心实验结果
#### （1）序列推荐性能对比（TIGER最优）
{{< figure src="/images/tiger/tiger_data_3.png" alt="" width="920" >}}
#### （2）消融实验：不同ID生成方式（RQ-VAE SID最优）
{{< figure src="/images/tiger/tiger_data_4.png" alt="" width="920" >}}
#### （3）冷启动推荐性能（TIGER优于KNN）
{{< figure src="/images/tiger/tiger_data_5.png" alt="" width="920" >}}

#### （4）推荐多样性（温度系数调控）
{{< figure src="/images/tiger/tiger_data_6.png" alt="" width="920" >}}

#### （5）模型层数与用户信息影响
{{< figure src="/images/tiger/tiger_data_7.png" alt="" width="920" >}}

#### （6）Invalid Semantic ID
{{< figure src="/images/tiger/tiger_data_6.png" alt="" width="920" >}}


### 模型成本与优势
####  成本分析
#### （1）内存成本
- 查找表：维护“物品ID→语义ID”和“语义ID→物品ID”两个哈希表，每个语义ID为4整数元组，大小约64N位（N为物品数）。
- 嵌入表：仅存储codebook中每个codeword的嵌入，远小于传统推荐系统的“物品-嵌入”表（传统需为每个物品存储嵌入）。

#### （2）推理成本
- 挑战：自回归解码+beam search，推理成本高于基于ANN的模型。
- 优化方向：探索更小模型结构或高效推理方法。

#### 核心优势
- 嵌入表规模可控：嵌入表基数不随物品空间线性增长，避免传统模型的大型嵌入表问题。
- 泛化能力强：支持冷启动推荐，可泛化到未见过的新物品。
- 生成式范式创新：将推荐从“检索匹配”转为“生成预测”，开辟新研究方向。


## 总结

#### 模型核心思路

- 本文提出了一种新的推荐范式，称为 **TIGER**，使用生成检索模型在序列推荐中“生成”下一个可能的交互对象。  
- 支撑该方法的是一种新的 **物品语义 ID 表示**，它在内容嵌入上使用多层量化器（**RQ-VAE**）来生成语义 ID。  
- 基于 **Transformer 的序列生成模型**：将用户的历史行为表示为语义 ID 序列，使用 **Encoder–Decoder** 结构的 Transformer 模型学习用户偏好，并生成下一个物品的语义 ID。  
- 嵌入表的基数不会随着物品空间的线性增长而增加，这使得训练过程中无需为每个单独物品建立大型嵌入表或索引系统，效率更高。  
- 在三个数据集上的实验表明，该模型能达到与 SOTA 检索模型相当的性能，同时具备泛化能力，可生成全新的或未见过的物品。

---

#### 不足

- 论文中的语义 ID 建模是静态的，没有与 user–item 交互相关联，也未融合协同信息。  
- 后续的生成式模型在动态交互建模和个性化生成方面仍有较大改进空间。

