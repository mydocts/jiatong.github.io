<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>博客 on Jiatong Blog</title><link>https://mydocts.github.io/jiatong.github.io/categories/%E5%8D%9A%E5%AE%A2/</link><description>Recent content in 博客 on Jiatong Blog</description><generator>Hugo</generator><language>en-US</language><lastBuildDate>Fri, 26 Dec 2025 00:00:00 +0000</lastBuildDate><atom:link href="https://mydocts.github.io/jiatong.github.io/categories/%E5%8D%9A%E5%AE%A2/index.xml" rel="self" type="application/rss+xml"/><item><title>NLP-Bookmark-Framework</title><link>https://mydocts.github.io/jiatong.github.io/posts/bookmark-framework/</link><pubDate>Fri, 26 Dec 2025 00:00:00 +0000</pubDate><guid>https://mydocts.github.io/jiatong.github.io/posts/bookmark-framework/</guid><description>&lt;h2 id="1-项目背景与动机"&gt;1. 项目背景与动机&lt;/h2&gt;
&lt;h3 id="核心问题"&gt;核心问题&lt;/h3&gt;
&lt;p&gt;在测试时扩展（Test-Time Scaling）场景下，大模型需要进行深度、多步骤推理（如数学竞赛题 AIME）。然而，现有方法面临两大挑战：&lt;/p&gt;</description></item><item><title>Translate-Paper</title><link>https://mydocts.github.io/jiatong.github.io/posts/translate/</link><pubDate>Tue, 23 Dec 2025 00:00:00 +0000</pubDate><guid>https://mydocts.github.io/jiatong.github.io/posts/translate/</guid><description>&lt;h3 id="项目背景"&gt;项目背景&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;目标&lt;/strong&gt;：构建一个专注于将英文论文翻译为流畅中文的垂直领域小模型。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;痛点分析&lt;/strong&gt;：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;现有工具问题&lt;/strong&gt;：传统的翻译工具（如 Google Translate）往往过于直译，缺乏学术语境的润色，读起来拗口。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;大模型限制&lt;/strong&gt;：SOTA 大模型（如 GPT-4）效果好但 API 成本高，且并发受限，不适合大规模文档处理。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;项目方案&lt;/strong&gt;：&lt;/p&gt;</description></item><item><title>LLM-RL-GRPO-and its Variants</title><link>https://mydocts.github.io/jiatong.github.io/posts/grpo-variants/</link><pubDate>Sun, 14 Dec 2025 00:00:00 +0000</pubDate><guid>https://mydocts.github.io/jiatong.github.io/posts/grpo-variants/</guid><description>&lt;p&gt;&lt;strong&gt;GRPO是针对LLM的一种改进PPO算法&lt;/strong&gt;&lt;/p&gt;
&lt;h1 id="回顾前置知识"&gt;回顾前置知识：&lt;/h1&gt;
&lt;h2 id="policy-gradient"&gt;Policy Gradient&lt;/h2&gt;
$$
\nabla_\theta J(\theta)
\approx 
\frac{1}{N} 
\sum_{n=1}^{N} 
\sum_{t=1}^{T_n} 
R(\tau^{(n)}) 
\nabla_\theta 
\log P_\theta(a_t^{(n)} \mid s_t^{(n)})
$$&lt;hr&gt;
&lt;p&gt;&lt;strong&gt;符号解释&lt;/strong&gt;&lt;/p&gt;
&lt;table&gt;
 &lt;thead&gt;
 &lt;tr&gt;
 &lt;th&gt;符号&lt;/th&gt;
 &lt;th&gt;含义&lt;/th&gt;
 &lt;/tr&gt;
 &lt;/thead&gt;
 &lt;tbody&gt;
 &lt;tr&gt;
 &lt;td&gt;$\nabla_\theta J(\theta)$&lt;/td&gt;
 &lt;td&gt;&lt;strong&gt;目标函数（期望回报）关于参数$\theta$的梯度&lt;/strong&gt;，即策略更新的方向。&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td&gt;$N$&lt;/td&gt;
 &lt;td&gt;&lt;strong&gt;采样的轨迹数量（episodes）&lt;/strong&gt;，即从环境中采样的完整回合数。&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td&gt;$T_n$&lt;/td&gt;
 &lt;td&gt;第$n$条轨迹的时间步数（episode的长度）。&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td&gt;$\tau^{(n)}$&lt;/td&gt;
 &lt;td&gt;第$n$条&lt;strong&gt;轨迹（trajectory）&lt;/strong&gt;：&lt;code&gt;&amp;lt;br&amp;gt;&lt;/code&gt; $\tau^{(n)} = (s_1^{(n)}, a_1^{(n)}, r_1^{(n)}, \dots, s_{T_n}^{(n)}, a_{T_n}^{(n)}, r_{T_n}^{(n)})$。&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td&gt;$R(\tau^{(n)})$&lt;/td&gt;
 &lt;td&gt;&lt;strong&gt;整条轨迹的总回报（return）&lt;/strong&gt;，通常为折扣累计奖励：&lt;code&gt;&amp;lt;br&amp;gt;&lt;/code&gt; $R(\tau^{(n)}) = \sum_{t=1}^{T_n}\gamma^{t-1}r_t^{(n)}$。&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td&gt;$\nabla_\theta \log P_\theta(a_t^{(n)}\mid s_t^{(n)})$&lt;/td&gt;
 &lt;td&gt;&lt;strong&gt;策略梯度项&lt;/strong&gt;，表示策略在状态$s_t^{(n)}$下选择动作$a_t^{(n)}$的对数概率的梯度，用于指导参数更新。&lt;/td&gt;
 &lt;/tr&gt;
 &lt;tr&gt;
 &lt;td&gt;$P_\theta(a_t^{(n)}\mid s_t^{(n)})$&lt;/td&gt;
 &lt;td&gt;&lt;strong&gt;参数化策略（policy）&lt;/strong&gt;，给定状态$s_t^{(n)}$时采取动作$a_t^{(n)}$的概率，由参数$\theta$控制。&lt;/td&gt;
 &lt;/tr&gt;
 &lt;/tbody&gt;
&lt;/table&gt;
&lt;hr&gt;
&lt;p&gt;&lt;strong&gt;直观理解&lt;/strong&gt;
这个公式的含义是：如果一条轨迹带来的总奖励$R(\tau)$很高，那么模型应该调整参数$\theta$，让在这条轨迹中采取的动作$a_t$的概率更高；反之则降低这些动作的概率。&lt;/p&gt;</description></item><item><title>LLM-RL-DPO</title><link>https://mydocts.github.io/jiatong.github.io/posts/dpo/</link><pubDate>Tue, 09 Dec 2025 00:00:00 +0000</pubDate><guid>https://mydocts.github.io/jiatong.github.io/posts/dpo/</guid><description>&lt;figure&gt;&lt;img src="https://mydocts.github.io/jiatong.github.io/images/ppo_full.png"
 alt="ppo" width="720"&gt;
&lt;/figure&gt;

&lt;figure&gt;&lt;img src="https://mydocts.github.io/jiatong.github.io/images/dpo_full.png"
 alt="dpo_full" width="720"&gt;
&lt;/figure&gt;

&lt;h3 id="kl-散度kullbackleibler-divergence"&gt;KL 散度（Kullback–Leibler Divergence）&lt;/h3&gt;
$$
KL(P \parallel Q) = \sum_{x \in X} P(x) \log \frac{P(x)}{Q(x)}
$$&lt;p&gt;&lt;strong&gt;含义&lt;/strong&gt;
P 分布相对于 Q 分布的相似程度。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;性质&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;KL 散度的值 &lt;strong&gt;大于等于 0&lt;/strong&gt;。&lt;/li&gt;
&lt;li&gt;P 和 Q 越相似，KL 散度越接近 0。&lt;/li&gt;
&lt;li&gt;如果 P 和 Q 分布完全一致，则 &lt;strong&gt;KL 散度 = 0&lt;/strong&gt;。&lt;/li&gt;
&lt;li&gt;注意：
$$
 KL(P \parallel Q) \neq KL(Q \parallel P)
 $$&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;KL 散度大于等于 0 的直观理解&lt;/strong&gt;
&lt;strong&gt;直观理解&lt;/strong&gt;：KL 散度是一个非负数，因为我们在比较两个分布时，
只有在完全一致时，它们之间的“差异”才为 0。&lt;/p&gt;</description></item><item><title>LLM-RL-PPO</title><link>https://mydocts.github.io/jiatong.github.io/posts/ppo/</link><pubDate>Sat, 06 Dec 2025 00:00:00 +0000</pubDate><guid>https://mydocts.github.io/jiatong.github.io/posts/ppo/</guid><description>&lt;figure&gt;&lt;img src="https://mydocts.github.io/jiatong.github.io/images/ppo_1.png"
 alt="前置基础" width="720"&gt;
&lt;/figure&gt;

&lt;h2 id="基础概念i"&gt;基础概念I&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;如果你不熟悉强化学习，学习ppo了解这些基础知识就足够了&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Action Space&lt;/strong&gt;: 可选择的动作，比如 {left, up, right}&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Policy&lt;/strong&gt;: 策略函数，输入 State，输出 Action 的概率分布。一般用 π 表示。&lt;/p&gt;</description></item><item><title>Some Obervations and Experience</title><link>https://mydocts.github.io/jiatong.github.io/posts/ai-thinking/</link><pubDate>Tue, 02 Dec 2025 00:00:00 +0000</pubDate><guid>https://mydocts.github.io/jiatong.github.io/posts/ai-thinking/</guid><description>&lt;h2 id="从工程实践看ai的本质"&gt;从工程实践看AI的本质&lt;/h2&gt;
&lt;p&gt;很多突破性的AI技术，其实都在模仿自然界已经存在了数百万年的机制。&lt;/p&gt;
&lt;p&gt;比如卷积神经网络的层级结构，本质上是在模拟视觉皮层的工作方式——从简单的边缘检测逐步抽象到复杂的物体识别。Transformer的自注意力机制，某种程度上也像是群体智能的数学建模，每个token都能&amp;quot;看到&amp;quot;全局，但各司其职。&lt;/p&gt;</description></item><item><title>Transformer</title><link>https://mydocts.github.io/jiatong.github.io/posts/transformer/</link><pubDate>Wed, 17 Sep 2025 00:00:00 +0000</pubDate><guid>https://mydocts.github.io/jiatong.github.io/posts/transformer/</guid><description>&lt;h1 id="transformer"&gt;Transformer&lt;/h1&gt;
&lt;figure&gt;&lt;img src="https://mydocts.github.io/jiatong.github.io/images/transformer/architecture.png" width="720"&gt;
&lt;/figure&gt;

&lt;h2 id="embedding"&gt;Embedding&lt;/h2&gt;
&lt;p&gt;下面的示例实现一个最简词嵌入层，附带缩放确保数值稳定。&lt;/p&gt;
&lt;div
 class="code-block-container border-border bg-card my-6 overflow-hidden rounded-xl border shadow-sm transition-all duration-200 ease-out hover:-translate-y-0.5 hover:shadow-md"&gt;
 
 &lt;div
 class="code-block-header bg-muted/30 border-border flex items-center justify-between border-b px-4 py-3"&gt;
 
 &lt;div class="flex items-center gap-2"&gt;
 &lt;div class="text-muted-foreground flex-shrink-0"&gt;
 &lt;svg class="h-4 w-4" fill="none" stroke="currentColor" viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"&gt;
 &lt;path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M10 20l4-16m4 4l4 4-4 4M6 16l-4-4 4-4" /&gt;
&lt;/svg&gt;
 &lt;/div&gt;
 &lt;span class="text-muted-foreground text-sm font-medium"&gt;
 PYTHON
 &lt;/span&gt;
 &lt;/div&gt;

 
 &lt;div class="flex items-center gap-2"&gt;
 &lt;button
 class="collapse-code-btn text-muted-foreground hover:text-primary hover:bg-primary/10 focus:ring-primary/20 flex items-center gap-1.5 rounded-md px-2 py-1 text-xs font-medium transition-all duration-200 ease-out focus:ring-2 focus:outline-none"
 data-code-id="code-0"
 data-default-state="expanded"
 data-collapsed="false"
 data-auto-collapse-lines="30"
 data-auto-collapse-height="400"
 data-collapsed-height="120"
 title="Collapse"
 aria-label="Collapse"&gt;
 &lt;span class="collapse-icon"&gt;
 &lt;svg class="h-3 w-3" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"&gt;&lt;path fill="currentColor" d="M7.41 15.41L12 10.83l4.59 4.58L18 14l-6-6l-6 6z"/&gt;&lt;/svg&gt;
 &lt;/span&gt;
 &lt;span class="collapse-text hidden sm:inline"
 &gt;Collapse&lt;/span
 &gt;
 &lt;/button&gt;
 &lt;button
 class="copy-code-btn text-muted-foreground hover:text-primary hover:bg-primary/10 focus:ring-primary/20 flex items-center gap-1.5 rounded-md px-2 py-1 text-xs font-medium transition-all duration-200 ease-out focus:ring-2 focus:outline-none"
 data-code-id="code-0"
 title="Copy"
 aria-label="Copy"&gt;
 &lt;span class="copy-icon"&gt;
 &lt;svg class="h-3 w-3" fill="none" stroke="currentColor" viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"&gt;
 &lt;path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M8 16H6a2 2 0 01-2-2V6a2 2 0 012-2h8a2 2 0 012 2v2m-6 12h8a2 2 0 002-2v-8a2 2 0 00-2-2h-8a2 2 0 00-2 2v8a2 2 0 002 2z" /&gt;
&lt;/svg&gt;
 &lt;/span&gt;
 &lt;span class="copy-text hidden sm:inline"
 &gt;Copy&lt;/span
 &gt;
 &lt;/button&gt;
 &lt;/div&gt;
 &lt;/div&gt;

 
 &lt;div class="code-block-content relative" id="code-0"&gt;
 &lt;div class="highlight"&gt;&lt;pre tabindex="0" class="chroma"&gt;&lt;code class="language-python" data-lang="python"&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;torch&lt;/span&gt; &lt;span class="c1"&gt;# 引入 PyTorch 用于张量运算&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;torch.nn&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;nn&lt;/span&gt; &lt;span class="c1"&gt;# 导入神经网络模块方便搭建组件&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt;&lt;span class="k"&gt;class&lt;/span&gt; &lt;span class="nc"&gt;SimpleEmbedding&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;nn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Module&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt; &lt;span class="c1"&gt;# 定义词嵌入层类&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="fm"&gt;__init__&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;vocab_size&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="nb"&gt;int&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;d_model&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="nb"&gt;int&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt; &lt;span class="c1"&gt;# 接收词表大小和向量维度&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="nb"&gt;super&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="fm"&gt;__init__&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt; &lt;span class="c1"&gt;# 初始化父类确保模块注册&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;embed&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;nn&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Embedding&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;vocab_size&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;d_model&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="c1"&gt;# 创建可学习的词嵌入矩阵&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;scale&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;d_model&lt;/span&gt; &lt;span class="o"&gt;**&lt;/span&gt; &lt;span class="mf"&gt;0.5&lt;/span&gt; &lt;span class="c1"&gt;# 保存缩放系数防止数值过小&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;forward&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;tokens&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;torch&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Tensor&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;-&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;torch&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Tensor&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="c1"&gt;# 定义前向传播&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class="line"&gt;&lt;span class="cl"&gt; &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;embed&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;tokens&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;scale&lt;/span&gt; &lt;span class="c1"&gt;# 查表并放大嵌入向量&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
 
 &lt;div
 class="collapse-overlay to-card/90 pointer-events-none absolute inset-0 bg-gradient-to-b from-transparent via-transparent opacity-0 transition-opacity duration-300"&gt;
 &lt;div
 class="text-muted-foreground bg-card/80 border-border/50 hover:bg-primary/10 hover:text-primary hover:border-primary/30 absolute bottom-4 left-1/2 -translate-x-1/2 cursor-pointer rounded-full border px-3 py-1.5 text-xs backdrop-blur-sm transition-all duration-200"&gt;
 Click to expand and view more
 &lt;/div&gt;
 &lt;/div&gt;
 &lt;/div&gt;
&lt;/div&gt;


&lt;script&gt;
(function() {
 const codeId = 'code-0';
 const copyBtn = document.querySelector('.copy-code-btn[data-code-id="' + codeId + '"]');
 const collapseBtn = document.querySelector('.collapse-code-btn[data-code-id="' + codeId + '"]');
 const codeContainer = document.getElementById(codeId);

 if (!codeContainer) return;

 
 if (copyBtn) {
 const copyIcon = copyBtn.querySelector('.copy-icon');
 const copyText = copyBtn.querySelector('.copy-text');

 copyBtn.addEventListener('click', async function() {
 try {
 
 let codeText = '';

 
 const codeTableCell = codeContainer.querySelector('.lntd:last-child code');
 if (codeTableCell) {
 codeText = codeTableCell.textContent || codeTableCell.innerText;
 } else {
 
 const codeElement = codeContainer.querySelector('code');
 if (codeElement) {
 
 const hasInlineLineNumbers = codeElement.querySelector('.ln');
 if (hasInlineLineNumbers) {
 
 const codeLines = codeElement.querySelectorAll('.cl');
 if (codeLines.length &gt; 0) {
 codeText = Array.from(codeLines)
 .map(line =&gt; {
 const text = line.textContent || line.innerText;
 
 return text.replace(/\n+$/, '');
 })
 .join('\n')
 .replace(/\n+$/, ''); 
 } else {
 
 const allText = codeElement.textContent || codeElement.innerText;
 codeText = allText.replace(/^\d+/gm, '').replace(/^\s+/gm, '');
 }
 } else {
 
 codeText = codeElement.textContent || codeElement.innerText;
 }
 } else {
 
 codeText = codeContainer.textContent || codeContainer.innerText;
 }
 }

 
 codeText = codeText.trim();

 
 await navigator.clipboard.writeText(codeText);

 
 copyIcon.innerHTML = `\u003csvg class=\u0022h-3 w-3\u0022 fill=\u0022none\u0022 stroke=\u0022currentColor\u0022 viewBox=\u00220 0 24 24\u0022 xmlns=\u0022http:\/\/www.w3.org\/2000\/svg\u0022\u003e\n \u003cpath stroke-linecap=\u0022round\u0022 stroke-linejoin=\u0022round\u0022 stroke-width=\u00222\u0022 d=\u0022M5 13l4 4L19 7\u0022 \/\u003e\n\u003c\/svg\u003e`;
 if (copyText) {
 copyText.textContent = 'Copied';
 }
 copyBtn.classList.add('text-green-600');

 
 setTimeout(() =&gt; {
 copyIcon.innerHTML = `\u003csvg class=\u0022h-3 w-3\u0022 fill=\u0022none\u0022 stroke=\u0022currentColor\u0022 viewBox=\u00220 0 24 24\u0022 xmlns=\u0022http:\/\/www.w3.org\/2000\/svg\u0022\u003e\n \u003cpath stroke-linecap=\u0022round\u0022 stroke-linejoin=\u0022round\u0022 stroke-width=\u00222\u0022 d=\u0022M8 16H6a2 2 0 01-2-2V6a2 2 0 012-2h8a2 2 0 012 2v2m-6 12h8a2 2 0 002-2v-8a2 2 0 00-2-2h-8a2 2 0 00-2 2v8a2 2 0 002 2z\u0022 \/\u003e\n\u003c\/svg\u003e`;
 if (copyText) {
 copyText.textContent = 'Copy';
 }
 copyBtn.classList.remove('text-green-600');
 }, 2000);

 } catch (err) {
 console.error('复制失败:', err);

 
 const range = document.createRange();
 const codeElement = codeContainer.querySelector('code') || codeContainer;
 range.selectNodeContents(codeElement);
 const selection = window.getSelection();
 selection.removeAllRanges();
 selection.addRange(range);

 
 if (copyText) {
 copyText.textContent = 'Selected';
 }

 setTimeout(() =&gt; {
 if (copyText) {
 copyText.textContent = 'Copy';
 }
 selection.removeAllRanges();
 }, 2000);
 }
 });
 }

 
 if (collapseBtn) {
 const collapseIcon = collapseBtn.querySelector('.collapse-icon');
 const collapseText = collapseBtn.querySelector('.collapse-text');
 const collapseOverlay = codeContainer.querySelector('.collapse-overlay');

 
 let codeElement = codeContainer.querySelector('pre.chroma');
 if (!codeElement) {
 codeElement = codeContainer.querySelector('pre');
 }

 const defaultState = collapseBtn.dataset.defaultState || 'expanded';
 const isCollapsedAttr = collapseBtn.dataset.collapsed === 'true';
 const autoCollapseLines = parseInt(collapseBtn.dataset.autoCollapseLines) || 30;
 const autoCollapseHeight = parseInt(collapseBtn.dataset.autoCollapseHeight) || 400;
 const collapsedHeight = parseInt(collapseBtn.dataset.collapsedHeight) || 120;

 let isCollapsed = false;

 
 function initCollapse() {
 
 const shouldCollapse = isCollapsedAttr ||
 defaultState === 'collapsed' ||
 shouldAutoCollapse();

 if (shouldCollapse) {
 setCollapsed(true, false); 
 }
 }

 function shouldAutoCollapse() {
 
 if (codeElement) {
 const lines = codeElement.querySelectorAll('.line, .cl');
 const height = codeElement.offsetHeight;
 return lines.length &gt; autoCollapseLines || height &gt; autoCollapseHeight;
 }

 
 const containerHeight = codeContainer.offsetHeight;
 if (containerHeight &gt; autoCollapseHeight) {
 return true;
 }

 
 const textContent = codeContainer.textContent || codeContainer.innerText || '';
 const estimatedLines = textContent.split('\n').length;
 return estimatedLines &gt; autoCollapseLines;
 }

 function setCollapsed(collapsed, animate = true) {
 if (!collapseOverlay) return;

 isCollapsed = collapsed;

 if (collapsed) {
 
 codeContainer.style.maxHeight = collapsedHeight + 'px';
 codeContainer.style.overflow = 'hidden';
 collapseOverlay.style.opacity = '1';
 collapseOverlay.style.pointerEvents = 'auto';

 
 collapseIcon.innerHTML = `\u003csvg class=\u0022h-3 w-3\u0022 fill=\u0022none\u0022 stroke=\u0022currentColor\u0022 viewBox=\u00220 0 24 24\u0022 xmlns=\u0022http:\/\/www.w3.org\/2000\/svg\u0022\u003e\n \u003cpath stroke-linecap=\u0022round\u0022 stroke-linejoin=\u0022round\u0022 stroke-width=\u00222\u0022 d=\u0022M19 9l-7 7-7-7\u0022 \/\u003e\n\u003c\/svg\u003e`;
 if (collapseText) {
 collapseText.textContent = 'Expand';
 }
 collapseBtn.title = 'Expand';

 } else {
 
 codeContainer.style.maxHeight = '';
 codeContainer.style.overflow = '';
 collapseOverlay.style.opacity = '0';
 collapseOverlay.style.pointerEvents = 'none';

 
 collapseIcon.innerHTML = `\u003csvg class=\u0022h-3 w-3\u0022 xmlns=\u0022http:\/\/www.w3.org\/2000\/svg\u0022 viewBox=\u00220 0 24 24\u0022\u003e\u003cpath fill=\u0022currentColor\u0022 d=\u0022M7.41 15.41L12 10.83l4.59 4.58L18 14l-6-6l-6 6z\u0022\/\u003e\u003c\/svg\u003e`;
 if (collapseText) {
 collapseText.textContent = 'Collapse';
 }
 collapseBtn.title = 'Collapse';
 }

 
 if (animate) {
 codeContainer.style.transition = 'max-height 0.3s ease-out';
 setTimeout(() =&gt; {
 codeContainer.style.transition = '';
 }, 300);
 }
 }

 function toggleCollapse() {
 setCollapsed(!isCollapsed, true);
 }

 
 collapseBtn.addEventListener('click', toggleCollapse);

 
 if (collapseOverlay) {
 collapseOverlay.addEventListener('click', () =&gt; {
 if (isCollapsed) {
 setCollapsed(false, true);
 }
 });
 }

 
 initCollapse();
 }
})();
&lt;/script&gt;
&lt;h2 id="muti_head-attention"&gt;Muti_Head Attention&lt;/h2&gt;
&lt;p&gt;下面的类展示如何把输入拆成多头并执行自注意力。&lt;/p&gt;</description></item></channel></rss>